{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from requests.models import PreparedRequest\n",
    "from urllib.request import Request, urlopen\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from typing import Optional\n",
    "\n",
    "import json\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from pydantic import Field\n",
    "import sys\n",
    "sys.path.append('/Users/williamharrigan/Desktop/hackathon/')\n",
    "from codes import *\n",
    "import pytz\n",
    "from enum import Enum\n",
    "\n",
    "from typing import Optional\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pytz\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from enum import Enum\n",
    "from typing import Optional, Dict, Any, List, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pytz\n",
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from pydantic import BaseModel\n",
    "\n",
    "output_dir = '/Users/williamharrigan/Desktop/hackathon/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_process_query = \"\"\"You are an AI assistant for the Hawai'i Climate Data Portal. \n",
    "You are responsible for answering the user query based on the results you get back from the tools.\n",
    "\n",
    "When a user asks a query, carefully analyze the query and determine the best way to respond to the following questions:\n",
    "1. What are the specific information the user is asking for?\n",
    "2. What tools do you need to use to get the information?\n",
    "3. What is the best way to format the response?\n",
    "\n",
    "Plan your response step by step using the available tools and respond with the final answer only.\n",
    "\n",
    "Output Format:\n",
    "Only respond with the final answer. Do not lead the user to more conversation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# prompt_process_query = \"\"\"You are a Concierge AI assistant for the Hawai'i Climate Data Portal (HCDP). Your primary job is to provide users accurate and reliable answers backed by the data extracted from the available tools. \n",
    "\n",
    "# Users may ask for two types of information:\n",
    "# 1. Climate data for a specific location and time period. You have access to the HCDP API, which provides climate data for various locations in Hawaii. You can use the API to get climate data such as temperature and rainfall for specific locations and time periods.\n",
    "# 2. General information about HCDP, including its purpose and how to access data. You can also provide general information about the HCDP web portal, including its purpose and how to access certain data.\n",
    "\n",
    "# When a user asks a query, carefully classify the query into one of the two categories mentioned above. If you are unable to classify the query, ask the user to clarify the question.\n",
    "\n",
    "# if the query is type 1: about climate data, fill in the following template:\n",
    "\n",
    "# aggregation: \"min\" | \"max\" | \"mean\", \n",
    "# period: \"day\" | \"month\" | \"year\",\n",
    "# location name: str,\n",
    "# start_date: Optional[str],\n",
    "# end_date: Optional[str]\n",
    "\n",
    "# Once you have the answers to the questions, plan your response step by step using the available tools and respond with the final answer only.\n",
    "\n",
    "# Output Format:\n",
    "# Only respond with the final answer in an easy to understand language. Do not lead the user to more conversation.\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_process_agent = Agent(  \n",
    "    \"groq:deepseek-r1-distill-llama-70b\",\n",
    "    result_type=str,    \n",
    "    system_prompt=prompt_process_query,\n",
    "    model_settings={'temperature': 0.0}    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt_process_agent = Agent(  \n",
    "#     \"google:gemini-1.5-flash\",  # Gemini model\n",
    "#     result_type=str,\n",
    "#     system_prompt=prompt_process_query,\n",
    "#     model_settings={'temperature': 0.0}    \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will be given a token to access the HCDP API. Add that token here.\n",
    "hcdp_api_token = os.environ[\"hcdp_api_token\"]\n",
    "# Please input your email address. This will be used for user logging or distributing data packages\n",
    "email = \"INSERT_EMAIL_ADDRESS_HERE\"\n",
    "\n",
    "api_base_url = \"https://api.hcdp.ikewai.org\"\n",
    "# Setup header for API requests\n",
    "header = {\n",
    "  \"Authorization\": f\"Bearer {hcdp_api_token}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions from the HCDP documentation\n",
    "\n",
    "def display_raster(params, title, cmap = plt.cm.viridis.reversed(), nodata_color = \"#f0f0f0\"):\n",
    "    #construct raster endpoint url base\n",
    "    raster_ep = \"/raster\"\n",
    "    url = f\"{api_base_url}{raster_ep}\"\n",
    "    #construct url with params\n",
    "    url_constructor = PreparedRequest()\n",
    "    url_constructor.prepare_url(url, params)\n",
    "    full_url = url_constructor.url\n",
    "    print(f\"Constructed API request URL: {full_url}\")\n",
    "    #create request object for use with urlopen\n",
    "    req = Request(full_url, headers = header)\n",
    "    #seupt plot\n",
    "    fig, ax = plt.subplots(figsize=(20, 10), facecolor = \"#e0e0e0\")\n",
    "    #remove axis ticks (displays row, col numbers, not super helpful)\n",
    "    ax.axes.get_xaxis().set_ticks([])\n",
    "    ax.axes.get_yaxis().set_ticks([])\n",
    "    #set plot title\n",
    "    plt.title(title, fontsize = 20)\n",
    "    #set nodata value\n",
    "    cmap.set_bad(nodata_color)\n",
    "    #open data stream from API\n",
    "    with urlopen(req) as raster:\n",
    "        #read tiff image\n",
    "        img = mpimg.imread(raster, format = \"tiff\")\n",
    "        #mask nodata values\n",
    "        masked = np.ma.masked_equal(img, img[0][0])\n",
    "        #plot on map with color schema and add color bar\n",
    "        imgplot = ax.imshow(masked[:, :, 0], cmap = cmap)\n",
    "        fig.colorbar(imgplot, ax = ax)\n",
    "        \n",
    "        \n",
    "def query_stations(values, name, limit = 10000, offset = 0):\n",
    "    params = {\n",
    "        \"name\": name\n",
    "    }\n",
    "    for key in values:\n",
    "        params[f\"value.{key}\"] = values[key]\n",
    "    params = {\n",
    "        \"q\": json.dumps(params),\n",
    "        \"limit\": limit,\n",
    "        \"offset\": offset\n",
    "    }\n",
    "\n",
    "    print(params)\n",
    "    \n",
    "    stations_ep = \"/stations\"\n",
    "    url = f\"{api_base_url}{stations_ep}\"\n",
    "\n",
    "    res = requests.get(url, params, headers = header)\n",
    "    res.raise_for_status()\n",
    "    print(f\"Constructed API request URL: {res.url}\")\n",
    "    res = [item[\"value\"] for item in res.json()[\"result\"]]\n",
    "    return res\n",
    "\n",
    "def get_station_metadata():\n",
    "    res = query_stations({}, name = \"hcdp_station_metadata\")\n",
    "    data = {}\n",
    "    for metadata in res:\n",
    "        data[metadata[metadata[\"id_field\"]]] = metadata\n",
    "    return data\n",
    "\n",
    "def get_station_data(values, metadata = None, limit = 10000, offset = 0):\n",
    "    res = query_stations(values, name = \"hcdp_station_value\", limit = limit, offset = offset)\n",
    "    combined = res\n",
    "    if metadata is not None:\n",
    "        combined = []\n",
    "        # combine values with metadata for station\n",
    "        for item in res:\n",
    "            station_metadata = metadata.get(item[\"station_id\"])\n",
    "            #only return data with metadata\n",
    "            if station_metadata is not None:\n",
    "                #combine item with metadata and add to combined array\n",
    "                combined.append(item | station_metadata)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataType(str, Enum):\n",
    "    TEMPERATURE = \"temperature\"\n",
    "    RAINFALL = \"rainfall\"\n",
    "    RELATIVE_HUMIDITY = \"relative_humidity\"\n",
    "    NDVI_MODIS = \"ndvi_modis\"\n",
    "    IGNITION_PROBABILITY = \"ignition_probability\"\n",
    "\n",
    "class Aggregation(str, Enum):\n",
    "    MIN = \"min\"\n",
    "    MAX = \"max\"\n",
    "    MEAN = \"mean\"\n",
    "\n",
    "class Production(str, Enum):\n",
    "    '''\n",
    "    Production can be \"new\" or \"legacy\". Legacy rainfall maps are available from 1920-2012, whereas new rainfall maps are available from 1990-present\n",
    "    '''\n",
    "    NEW = \"new\"\n",
    "    LEGACY = \"legacy\"\n",
    "\n",
    "class Period(str, Enum):\n",
    "    '''\n",
    "    This is the resolution of the datapoints. NDVI_MODIS only has a DAY resolution. If user asks for year or month for NDVI, return DAY\n",
    "    '''\n",
    "    \n",
    "    DAY = \"day\"\n",
    "    MONTH = \"month\"\n",
    "    YEAR = \"year\"\n",
    "\n",
    "class Extent(str, Enum):\n",
    "    '''\n",
    "    HAWAII = Big Island, Hawai'i\n",
    "    KAUAI = Kauai island, Hawai'i\n",
    "    HONOLULU = O'ahu island, Hawai'i\n",
    "    MAUI = Maui island\n",
    "    STATEWIDE = any time latitude and longitude coordinates are input, extent = statewide    \n",
    "    '''\n",
    "    STATEWIDE = \"statewide\"  # Data for the whole state\n",
    "    HAWAII = \"bi\"            # Hawaii county\n",
    "    KAUAI = \"ka\"             # Kauai county\n",
    "    MAUI = \"mn\"              # Maui county\n",
    "    HONOLULU = \"oa\"          # Honolulu county\n",
    "\n",
    "class ClimateDataParams(BaseModel):\n",
    "    datatype: DataType\n",
    "    period: Period\n",
    "    start: str\n",
    "    end: str\n",
    "    extent: Extent\n",
    "    lat: Optional[float] = None\n",
    "    lng: Optional[float] = None\n",
    "    # Optional fields that differ between temperature and rainfall\n",
    "    aggregation: Optional[Aggregation] = None\n",
    "    production: Optional[Production] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ClimateAPI:     \n",
    "    def __init__(self, api_base_url: str, header: Dict[str, str]):         \n",
    "        self.api_base_url = api_base_url         \n",
    "        self.header = header         \n",
    "        self.raster_timeseries_ep = \"/raster/timeseries\"              \n",
    "\n",
    "    def get_timeseries_data(self, params: ClimateDataParams) -> pd.DataFrame:         \n",
    "        \"\"\"Get timeseries data from the API based on provided parameters\"\"\"         \n",
    "        url = f\"{self.api_base_url}{self.raster_timeseries_ep}\"                  \n",
    "        params_dict = params.model_dump()\n",
    "        \n",
    "        # Remove None values from params\n",
    "        params_dict = {k: v for k, v in params_dict.items() if v is not None}\n",
    "                  \n",
    "        res = requests.get(url, params_dict, headers=self.header)         \n",
    "        res.raise_for_status()         \n",
    "        print(f\"Constructed API request URL: {res.url}\")                  \n",
    "        data = res.json()         \n",
    "        df_data = list(data.items())                  \n",
    "        \n",
    "        # Determine value column name based on datatype\n",
    "        if params.datatype == DataType.TEMPERATURE:\n",
    "            value_col = f\"{params.aggregation.value.capitalize()} {params.datatype.value.capitalize()} (°C)\"\n",
    "        else:  # For rainfall\n",
    "            value_col = f\"{params.datatype.value.capitalize()} (mm)\"\n",
    "                  \n",
    "        df = pd.DataFrame(df_data, columns=[\"Date\", value_col])         \n",
    "        df = df.sort_values(by=\"Date\")                  \n",
    "        return df   \n",
    "\n",
    "    def plot_timeseries(self, df: pd.DataFrame, params: ClimateDataParams) -> None:\n",
    "        \"\"\"Line plot of timeseries data using Plotly. This is specifically for plotting a variable over time. Always output HTML unless specifically told not to.\"\"\"\n",
    "        value_col = df.columns[1]  # Second column contains the values\n",
    "        \n",
    "        # Create appropriate title based on params\n",
    "        if params.datatype == DataType.TEMPERATURE:\n",
    "            title = f\"Summary of {params.aggregation.value} {params.datatype.value} from {params.start} to {params.end}\"\n",
    "        else:\n",
    "            title = f\"Summary of {params.datatype.value} from {params.start} to {params.end}\"\n",
    "            \n",
    "        if params.lat is not None and params.lng is not None:\n",
    "            title += f\" for location Latitude: {params.lat}, Longitude: {params.lng}\"\n",
    "            \n",
    "        fig = px.line(df, title=title, x=\"Date\", y=value_col)\n",
    "        fig.write_html(f\"{output_dir}/ndvis.html\")\n",
    "        return fig\n",
    "\n",
    "@prompt_process_agent.tool_plain  \n",
    "def get_temperature_timeseries(     \n",
    "    aggregation: Aggregation,     \n",
    "    period: Period,     \n",
    "    lat: float,     \n",
    "    lng: float,     \n",
    "    start_date: Optional[str] = None,      \n",
    "    end_date: Optional[str] = None,\n",
    "    extent: Optional[Extent] = Extent.STATEWIDE\n",
    ") -> Dict[str, Any]:     \n",
    "    \"\"\"Return temperature timeseries data for the specified location, period and aggregation\"\"\"     \n",
    "    api = ClimateAPI(api_base_url=api_base_url, header=header)     \n",
    "    print(\"API initialized:\", api)          \n",
    "\n",
    "    today = datetime.now(pytz.timezone(\"US/Hawaii\"))     \n",
    "    yesterday = today - timedelta(days=1)     \n",
    "    previous_year = today - relativedelta(years=1)          \n",
    "\n",
    "    start_str = start_date if start_date else previous_year.strftime(\"%Y-%m-%d\")     \n",
    "    end_str = end_date if end_date else yesterday.strftime(\"%Y-%m-%d\")          \n",
    "\n",
    "    # Create params for temperature (requires aggregation)\n",
    "    params = ClimateDataParams(         \n",
    "        datatype=DataType.TEMPERATURE,         \n",
    "        aggregation=aggregation,         \n",
    "        period=period,         \n",
    "        start=start_str,         \n",
    "        end=end_str,         \n",
    "        # extent=extent,     \n",
    "        extent=\"statewide\",   \n",
    "        lat=lat,         \n",
    "        lng=lng     \n",
    "    )          \n",
    "\n",
    "    print(\"Query parameters:\", params)          \n",
    "\n",
    "    df = api.get_timeseries_data(params)          \n",
    "\n",
    "    # Return structured result with data preview + summary     \n",
    "    result = {         \n",
    "        \"data_preview\": df.head(5).to_dict(orient=\"records\") + df.tail(5).to_dict(orient=\"records\"),\n",
    "        \"summary\": {             \n",
    "            \"mean\": df.iloc[:, 1].mean(),             \n",
    "            \"min\": df.iloc[:, 1].min(),             \n",
    "            \"max\": df.iloc[:, 1].max(),             \n",
    "            \"location\": {\"lat\": lat, \"lng\": lng},             \n",
    "            \"period\": f\"{start_str} to {end_str}\"         \n",
    "        }     \n",
    "    }\n",
    "\n",
    "    # Plot the time series if data exists and has a \"Date\" column\n",
    "    if not df.empty and \"Date\" in df.columns:\n",
    "        api.plot_timeseries(df, params)\n",
    "        print(\"Time series plot has been generated.\")\n",
    "    else:\n",
    "        print(\"No time series data available for plotting.\")\n",
    "     \n",
    "    return result  \n",
    "\n",
    "@prompt_process_agent.tool_plain  \n",
    "def get_rainfall_timeseries(     \n",
    "    period: Period,     \n",
    "    lat: float,     \n",
    "    lng: float,     \n",
    "    start_date: Optional[str] = None,      \n",
    "    end_date: Optional[str] = None,\n",
    "    production: Production = Production.NEW,\n",
    "    extent: Optional[Extent] = Extent.STATEWIDE\n",
    ") -> Dict[str, Any]:     \n",
    "    \"\"\"Return the max, mean and min of the rainfall data. Keep it concise.\"\"\"     \n",
    "    api = ClimateAPI(api_base_url=api_base_url, header=header)     \n",
    "    print(\"API initialized:\", api)          \n",
    "\n",
    "    today = datetime.now(pytz.timezone(\"US/Hawaii\"))     \n",
    "    yesterday = today - timedelta(days=1)     \n",
    "    previous_year = today - relativedelta(years=1)          \n",
    "\n",
    "    start_str = start_date if start_date else previous_year.strftime(\"%Y-%m-%d\")     \n",
    "    end_str = end_date if end_date else yesterday.strftime(\"%Y-%m-%d\")          \n",
    "\n",
    "    # Create params for rainfall (requires production instead of aggregation)\n",
    "    params = ClimateDataParams(         \n",
    "        datatype=DataType.RAINFALL,         \n",
    "        production=\"new\",         \n",
    "        period=period, \n",
    "        start = start_str,\n",
    "        end = end_str,\n",
    "        extent=\"statewide\",    \n",
    "        lat=lat,         \n",
    "        lng=lng     \n",
    "    )      \n",
    "    \n",
    "    print(\"Query parameters:\", params)          \n",
    "\n",
    "    df = api.get_timeseries_data(params)          \n",
    "\n",
    "    # Return structured result with data preview + summary     \n",
    "    result = {         \n",
    "        \"data_preview\": df.head(5).to_dict(orient=\"records\") + df.tail(5).to_dict(orient=\"records\"),\n",
    "        \"summary\": {             \n",
    "            \"mean\": df.iloc[:, 1].mean(),             \n",
    "            \"min\": df.iloc[:, 1].min(),             \n",
    "            \"max\": df.iloc[:, 1].max(),             \n",
    "            \"location\": {\"lat\": lat, \"lng\": lng},             \n",
    "            \"period\": f\"{start_str} to {end_str}\"         \n",
    "        }     \n",
    "    }\n",
    "\n",
    "    # Plot the time series if data exists and has a \"Date\" column\n",
    "    if not df.empty and \"Date\" in df.columns:\n",
    "        api.plot_timeseries(df, params)\n",
    "        print(\"Time series plot has been generated.\")\n",
    "    else:\n",
    "        print(\"No time series data available for plotting.\")\n",
    "     \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@prompt_process_agent.tool_plain  \n",
    "def get_relative_humidity_timeseries(     \n",
    "    period: Period,     \n",
    "    lat: float,     \n",
    "    lng: float,     \n",
    "    start_date: Optional[str] = None,      \n",
    "    end_date: Optional[str] = None,\n",
    "    # production: Production = Production.NEW,\n",
    "    extent: Optional[Extent] = Extent.STATEWIDE\n",
    ") -> Dict[str, Any]:     \n",
    "    \"\"\"Return the max, mean and min relative humidity for the queried location. Keep it concise.\"\"\"     \n",
    "    api = ClimateAPI(api_base_url=api_base_url, header=header)     \n",
    "    print(\"API initialized:\", api)          \n",
    "\n",
    "    today = datetime.now(pytz.timezone(\"US/Hawaii\"))     \n",
    "    yesterday = today - timedelta(days=1)     \n",
    "    previous_year = today - relativedelta(years=1)          \n",
    "\n",
    "    start_str = start_date if start_date else previous_year.strftime(\"%Y-%m-%d\")     \n",
    "    end_str = end_date if end_date else yesterday.strftime(\"%Y-%m-%d\")          \n",
    "\n",
    "    # Create params for rainfall (requires production instead of aggregation)\n",
    "    params = ClimateDataParams(         \n",
    "        datatype=DataType.RELATIVE_HUMIDITY,         \n",
    "        # production=\"new\",         \n",
    "        period=\"day\", \n",
    "        start = start_str,\n",
    "        end = end_str,\n",
    "        extent=\"statewide\",    \n",
    "        lat=lat,         \n",
    "        lng=lng     \n",
    "    )      \n",
    "    \n",
    "    print(\"Query parameters:\", params)          \n",
    "\n",
    "    df = api.get_timeseries_data(params)          \n",
    "\n",
    "    # Return structured result with data preview + summary     \n",
    "    result = {         \n",
    "        \"data_preview\": df.head(5).to_dict(orient=\"records\") + df.tail(5).to_dict(orient=\"records\"),\n",
    "        \"summary\": {             \n",
    "            \"mean\": df.iloc[:, 1].mean(),             \n",
    "            \"min\": df.iloc[:, 1].min(),             \n",
    "            \"max\": df.iloc[:, 1].max(),             \n",
    "            \"location\": {\"lat\": lat, \"lng\": lng},             \n",
    "            \"period\": f\"{start_str} to {end_str}\"         \n",
    "        }     \n",
    "    }\n",
    "\n",
    "    # Plot the time series if data exists and has a \"Date\" column\n",
    "    if not df.empty and \"Date\" in df.columns:\n",
    "        api.plot_timeseries(df, params)\n",
    "        print(\"Time series plot has been generated.\")\n",
    "    else:\n",
    "        print(\"No time series data available for plotting.\")\n",
    "     \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'day' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129;43m@prompt_process_agent\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_plain\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mget_vegetation_data_timeseries\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m     \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mday\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlat\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlng\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# production: Production = Production.NEW,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextent\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mExtent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mExtent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTATEWIDE\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m     \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"NDVI is an index quanitying vegetation health and density. Return the max, mean and min NDVI number for the query. Keep it concise.\"\"\"\u001b[39;49;00m\u001b[43m     \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mClimateAPI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_base_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m     \u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_base/lib/python3.12/site-packages/pydantic_ai/agent.py:936\u001b[0m, in \u001b[0;36mAgent.tool_plain\u001b[0;34m(self, func, retries, prepare, docstring_format, require_parameter_descriptions)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tool_decorator\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocstring_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire_parameter_descriptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_base/lib/python3.12/site-packages/pydantic_ai/agent.py:950\u001b[0m, in \u001b[0;36mAgent._register_function\u001b[0;34m(self, func, takes_ctx, retries, prepare, docstring_format, require_parameter_descriptions)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to register a function as a tool.\"\"\"\u001b[39;00m\n\u001b[1;32m    949\u001b[0m retries_ \u001b[38;5;241m=\u001b[39m retries \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_retries\n\u001b[0;32m--> 950\u001b[0m tool \u001b[38;5;241m=\u001b[39m \u001b[43mTool\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAgentDepsT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtakes_ctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtakes_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprepare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocstring_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocstring_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_parameter_descriptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_parameter_descriptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_tool(tool)\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_base/lib/python3.12/typing.py:1175\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inst:\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be instantiated; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__origin__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1175\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__origin__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1177\u001b[0m     result\u001b[38;5;241m.\u001b[39m__orig_class__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_base/lib/python3.12/site-packages/pydantic_ai/tools.py:230\u001b[0m, in \u001b[0;36mTool.__init__\u001b[0;34m(self, function, takes_ctx, max_retries, name, description, prepare, docstring_format, require_parameter_descriptions)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m takes_ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     takes_ctx \u001b[38;5;241m=\u001b[39m _pydantic\u001b[38;5;241m.\u001b[39mtakes_ctx(function)\n\u001b[0;32m--> 230\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43m_pydantic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakes_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocstring_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire_parameter_descriptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction \u001b[38;5;241m=\u001b[39m function\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtakes_ctx \u001b[38;5;241m=\u001b[39m takes_ctx\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_base/lib/python3.12/site-packages/pydantic_ai/_pydantic.py:64\u001b[0m, in \u001b[0;36mfunction_schema\u001b[0;34m(function, takes_ctx, docstring_format, require_parameter_descriptions)\u001b[0m\n\u001b[1;32m     60\u001b[0m gen_schema \u001b[38;5;241m=\u001b[39m _generate_schema\u001b[38;5;241m.\u001b[39mGenerateSchema(config_wrapper)\n\u001b[1;32m     62\u001b[0m sig \u001b[38;5;241m=\u001b[39m signature(function)\n\u001b[0;32m---> 64\u001b[0m type_hints \u001b[38;5;241m=\u001b[39m \u001b[43m_typing_extra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_function_type_hints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m var_kwargs_schema: core_schema\u001b[38;5;241m.\u001b[39mCoreSchema \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     67\u001b[0m fields: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, core_schema\u001b[38;5;241m.\u001b[39mTypedDictField] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_base/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:730\u001b[0m, in \u001b[0;36mget_function_type_hints\u001b[0;34m(function, include_keys, globalns, localns)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    728\u001b[0m         value \u001b[38;5;241m=\u001b[39m _make_forward_ref(value)\n\u001b[0;32m--> 730\u001b[0m     type_hints[name] \u001b[38;5;241m=\u001b[39m \u001b[43meval_type_backport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobalns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m type_hints\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_base/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:609\u001b[0m, in \u001b[0;36meval_type_backport\u001b[0;34m(value, globalns, localns, type_params)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"An enhanced version of `typing._eval_type` which will fall back to using the `eval_type_backport`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03mpackage if it's installed to let older Python versions use newer typing constructs.\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03mThis function will also display a helpful error if the value passed fails to evaluate.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eval_type_backport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobalns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to evaluate type annotation\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_base/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:633\u001b[0m, in \u001b[0;36m_eval_type_backport\u001b[0;34m(value, globalns, localns, type_params)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_eval_type_backport\u001b[39m(\n\u001b[1;32m    627\u001b[0m     value: Any,\n\u001b[1;32m    628\u001b[0m     globalns: GlobalsNamespace \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    629\u001b[0m     localns: MappingNamespace \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    630\u001b[0m     type_params: \u001b[38;5;28mtuple\u001b[39m[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eval_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobalns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(value, typing\u001b[38;5;241m.\u001b[39mForwardRef) \u001b[38;5;129;01mand\u001b[39;00m is_backport_fixable_error(e)):\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_base/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:667\u001b[0m, in \u001b[0;36m_eval_type\u001b[0;34m(value, globalns, localns, type_params)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m typing\u001b[38;5;241m.\u001b[39m_eval_type(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    664\u001b[0m         value, globalns, localns, type_params\u001b[38;5;241m=\u001b[39mtype_params\n\u001b[1;32m    665\u001b[0m     )\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobalns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalns\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_base/lib/python3.12/typing.py:415\u001b[0m, in \u001b[0;36m_eval_type\u001b[0;34m(t, globalns, localns, type_params, recursive_guard)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate all forward references in the given type t.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03mFor use of globalns and localns see the docstring for get_type_hints().\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03mrecursive_guard is used to prevent infinite recursion with a recursive\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03mForwardRef.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, ForwardRef):\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobalns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive_guard\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecursive_guard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (_GenericAlias, GenericAlias, types\u001b[38;5;241m.\u001b[39mUnionType)):\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, GenericAlias):\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_base/lib/python3.12/typing.py:938\u001b[0m, in \u001b[0;36mForwardRef._evaluate\u001b[0;34m(self, globalns, localns, type_params, recursive_guard)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    936\u001b[0m     locals_to_pass \u001b[38;5;241m=\u001b[39m localns\n\u001b[1;32m    937\u001b[0m type_ \u001b[38;5;241m=\u001b[39m _type_check(\n\u001b[0;32m--> 938\u001b[0m     \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__forward_code__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobalns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocals_to_pass\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward references must evaluate to types.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    940\u001b[0m     is_argument\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__forward_is_argument__,\n\u001b[1;32m    941\u001b[0m     allow_special_forms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__forward_is_class__,\n\u001b[1;32m    942\u001b[0m )\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__forward_value__ \u001b[38;5;241m=\u001b[39m _eval_type(\n\u001b[1;32m    944\u001b[0m     type_,\n\u001b[1;32m    945\u001b[0m     globalns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    948\u001b[0m     recursive_guard\u001b[38;5;241m=\u001b[39m(recursive_guard \u001b[38;5;241m|\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__forward_arg__}),\n\u001b[1;32m    949\u001b[0m )\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__forward_evaluated__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'day' is not defined"
     ]
    }
   ],
   "source": [
    "@prompt_process_agent.tool_plain  \n",
    "def get_vegetation_data_timeseries(     \n",
    "    period: \"day\",     \n",
    "    lat: float,     \n",
    "    lng: float,     \n",
    "    start_date: Optional[str] = None,      \n",
    "    end_date: Optional[str] = None,\n",
    "    # production: Production = Production.NEW,\n",
    "    extent: Optional[Extent] = Extent.STATEWIDE\n",
    ") -> Dict[str, Any]:     \n",
    "    \"\"\"NDVI is an index quanitying vegetation health and density. Return the max, mean and min NDVI number for the query. Keep it concise.\"\"\"     \n",
    "    api = ClimateAPI(api_base_url=api_base_url, header=header)     \n",
    "    print(\"API initialized:\", api)          \n",
    "\n",
    "    today = datetime.now(pytz.timezone(\"US/Hawaii\"))     \n",
    "    yesterday = today - timedelta(days=1)     \n",
    "    previous_year = today - relativedelta(years=1)          \n",
    "\n",
    "    start_str = start_date if start_date else previous_year.strftime(\"%Y-%m-%d\")     \n",
    "    end_str = end_date if end_date else yesterday.strftime(\"%Y-%m-%d\")          \n",
    "\n",
    "    # Create params for rainfall (requires production instead of aggregation)\n",
    "    params = ClimateDataParams(         \n",
    "        datatype=\"ndvi_modis\",         \n",
    "        # production=\"new\",         \n",
    "        period=period, \n",
    "        start = start_str,\n",
    "        end = end_str,\n",
    "        extent=\"statewide\",    \n",
    "        lat=lat,         \n",
    "        lng=lng     \n",
    "    )      \n",
    "    \n",
    "    print(\"Query parameters:\", params)          \n",
    "\n",
    "    df = api.get_timeseries_data(params)          \n",
    "\n",
    "    # Return structured result with data preview + summary     \n",
    "    result = {         \n",
    "        \"data_preview\": df.head(5).to_dict(orient=\"records\") + df.tail(5).to_dict(orient=\"records\"),\n",
    "        \"summary\": {             \n",
    "            \"mean\": df.iloc[:, 1].mean(),             \n",
    "            \"min\": df.iloc[:, 1].min(),             \n",
    "            \"max\": df.iloc[:, 1].max(),             \n",
    "            \"location\": {\"lat\": lat, \"lng\": lng},             \n",
    "            \"period\": f\"{start_str} to {end_str}\"         \n",
    "        }     \n",
    "    }\n",
    "\n",
    "    # Plot the time series if data exists and has a \"Date\" column\n",
    "    if not df.empty and \"Date\" in df.columns:\n",
    "        api.plot_timeseries(df, params)\n",
    "        print(\"Time series plot has been generated.\")\n",
    "    else:\n",
    "        print(\"No time series data available for plotting.\")\n",
    "     \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@prompt_process_agent.tool_plain  \n",
    "def get_ignition_probability_timeseries(     \n",
    "    period: str,     \n",
    "    lat: float,     \n",
    "    lng: float,     \n",
    "    start_date: Optional[str] = None,      \n",
    "    end_date: Optional[str] = None,\n",
    "    # production: Production = Production.NEW,\n",
    "    extent: Optional[Extent] = Extent.STATEWIDE\n",
    ") -> Dict[str, Any]:     \n",
    "    \"\"\"The ignition probability product shows the daily probability of large (8+ acre) fire ignitions based on current and past climate. Keep it concise.\"\"\"     \n",
    "    api = ClimateAPI(api_base_url=api_base_url, header=header)     \n",
    "    print(\"API initialized:\", api)          \n",
    "\n",
    "    today = datetime.now(pytz.timezone(\"US/Hawaii\"))     \n",
    "    yesterday = today - timedelta(days=1)     \n",
    "    previous_year = today - relativedelta(years=1)          \n",
    "\n",
    "    start_str = start_date if start_date else previous_year.strftime(\"%Y-%m-%d\")     \n",
    "    end_str = end_date if end_date else yesterday.strftime(\"%Y-%m-%d\")          \n",
    "\n",
    "    # Create params for rainfall (requires production instead of aggregation)\n",
    "    params = ClimateDataParams(         \n",
    "        datatype=\"ignition_probability\",         \n",
    "        # production=\"new\",         \n",
    "        period=\"day\", \n",
    "        start = start_str,\n",
    "        end = end_str,\n",
    "        extent=\"statewide\",    \n",
    "        lat=lat,         \n",
    "        lng=lng     \n",
    "    )      \n",
    "    \n",
    "    print(\"Query parameters:\", params)          \n",
    "\n",
    "    df = api.get_timeseries_data(params)          \n",
    "\n",
    "    # Return structured result with data preview + summary     \n",
    "    result = {         \n",
    "        \"data_preview\": df.head(5).to_dict(orient=\"records\") + df.tail(5).to_dict(orient=\"records\"),\n",
    "        \"summary\": {             \n",
    "            \"mean\": df.iloc[:, 1].mean(),             \n",
    "            \"min\": df.iloc[:, 1].min(),             \n",
    "            \"max\": df.iloc[:, 1].max(),             \n",
    "            \"location\": {\"lat\": lat, \"lng\": lng},             \n",
    "            \"period\": f\"{start_str} to {end_str}\"         \n",
    "        }     \n",
    "    }\n",
    "\n",
    "    # Plot the time series if data exists and has a \"Date\" column\n",
    "    if not df.empty and \"Date\" in df.columns:\n",
    "        api.plot_timeseries(df, params)\n",
    "        print(\"Time series plot has been generated.\")\n",
    "    else:\n",
    "        print(\"No time series data available for plotting.\")\n",
    "     \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await prompt_process_agent.run(\"Plot daily relative humidity from August 2005 to August 2008 at the coordinates lat:21.301035061407028,lng:-157.81837141983394?\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await prompt_process_agent.run(\"Plot daily vegatation cover from August 2005 to August 2018 at the coordinates lat:21.298964,lng:-157.808784? Also tell me the max NDVI and the day it corresponds to within that time period.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API initialized: <__main__.ClimateAPI object at 0x16804fe60>\n",
      "Query parameters: datatype=<DataType.IGNITION_PROBABILITY: 'ignition_probability'> period=<Period.DAY: 'day'> start='2005-08-01' end='2018-08-31' extent=<Extent.STATEWIDE: 'statewide'> lat=21.298964 lng=-157.808784 aggregation=None production=None\n",
      "Constructed API request URL: https://api.hcdp.ikewai.org/raster/timeseries?datatype=ignition_probability&period=day&start=2005-08-01&end=2018-08-31&extent=statewide&lat=21.298964&lng=-157.808784\n",
      "Time series plot has been generated.\n",
      "API initialized: <__main__.ClimateAPI object at 0x16a699130>\n",
      "Query parameters: datatype=<DataType.IGNITION_PROBABILITY: 'ignition_probability'> period=<Period.DAY: 'day'> start='2005-08-01' end='2018-08-31' extent=<Extent.STATEWIDE: 'statewide'> lat=21.298964 lng=-157.808784 aggregation=None production=None\n",
      "Constructed API request URL: https://api.hcdp.ikewai.org/raster/timeseries?datatype=ignition_probability&period=day&start=2005-08-01&end=2018-08-31&extent=statewide&lat=21.298964&lng=-157.808784\n",
      "Time series plot has been generated.\n",
      "API initialized: <__main__.ClimateAPI object at 0x16a69aa20>\n",
      "Query parameters: datatype=<DataType.IGNITION_PROBABILITY: 'ignition_probability'> period=<Period.DAY: 'day'> start='2005-08-01' end='2018-08-31' extent=<Extent.STATEWIDE: 'statewide'> lat=21.298964 lng=-157.808784 aggregation=None production=None\n",
      "Constructed API request URL: https://api.hcdp.ikewai.org/raster/timeseries?datatype=ignition_probability&period=day&start=2005-08-01&end=2018-08-31&extent=statewide&lat=21.298964&lng=-157.808784\n",
      "Time series plot has been generated.\n"
     ]
    }
   ],
   "source": [
    "r = await prompt_process_agent.run(\"Show me the fire probability from August 2005 to August 2018 at the coordinates lat:21.298964,lng:-157.808784?.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await prompt_process_agent.run(\"What was the daily rainfall from August 2020 to August 2022 at the coordinates lat:21.301035061407028,lng:-157.81837141983394? Plot the rainfall timeseries.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await prompt_process_agent.run(\"What was the mean temperature from August 2020 to August 2022 at the coordinates lat:21.301035061407028,lng:-157.81837141983394? Plot how the mean temperature changed everyday within that time range.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await prompt_process_agent.run(\"What was the mean temperature from August 2020 to August 2022 at the coordinates lat:21.501947,lng:-157.966537? Plot how the mean temperature changed everyday within that time range.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await prompt_process_agent.run(\"Give me the max temperature monthly from August 1990 to August 2000 in coordinates [21.3069, -157.8583]?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await prompt_process_agent.run(\"What was the max temperature yesterday at random lat/long coordinates on Kauai Island, Hawai'i?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await prompt_process_agent.run(\"What was the max temperature today at 19.5, -155.5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
